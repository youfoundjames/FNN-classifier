{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad4ecbc",
   "metadata": {},
   "source": [
    "Here is a complete machine learning pipeline built in TensorFlow which uses a simple feedforward neural network (FNN) to classify the famous Iris dataset, which contains measurements of 150 iris flowers from three different species. Each sample from the dataset contains 4 features corresponding to petal length, petal width, sepal length, and sepal width. (*Sepals* are the green leafy parts of a flower directly underneath its petals.) Our goal is to build a model that can predict the species of an iris flower based on these measurements.\n",
    "\n",
    "First we import and preprocess the dataset, and perform a train/test split, allocating 80% of the dataset to training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2094ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 00:05:23.538519: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "inputs = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "inputs_train, inputs_test, labels_train, labels_test = train_test_split(inputs, labels, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54c983",
   "metadata": {},
   "source": [
    "Next, we build and compile a 4-layer FNN. The final layer has 3 nodes corresponding to the 3 classes into which we wish to classify the data. The dataset is pretty simple so 10 nodes per layer should be sufficient. Using 4 layers we can pretty consistently get 100% accuracy.\n",
    "When we compile, we will optimize the model for a simple accuracy metric using an optimized gradient descent algorithm called Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd34493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(4,)),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'] # using a simple accuracy metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d5922",
   "metadata": {},
   "source": [
    "Next, we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5260200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0227 - loss: 1.0954 - val_accuracy: 0.3000 - val_loss: 1.0827\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4775 - loss: 1.0731 - val_accuracy: 0.5333 - val_loss: 1.0421\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6315 - loss: 1.0270 - val_accuracy: 0.5667 - val_loss: 1.0044\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.9961 - val_accuracy: 0.5000 - val_loss: 0.9545\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6764 - loss: 0.9235 - val_accuracy: 0.5667 - val_loss: 0.9091\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7782 - loss: 0.8367 - val_accuracy: 0.5667 - val_loss: 0.8538\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.8258 - val_accuracy: 0.6667 - val_loss: 0.8063\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.7976 - val_accuracy: 0.8000 - val_loss: 0.7657\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.7407 - val_accuracy: 0.9000 - val_loss: 0.7292\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8471 - loss: 0.6379 - val_accuracy: 0.9667 - val_loss: 0.7022\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9337 - loss: 0.6377 - val_accuracy: 0.9667 - val_loss: 0.6646\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.6523 - val_accuracy: 0.9667 - val_loss: 0.6366\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.5522 - val_accuracy: 0.9667 - val_loss: 0.6031\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.6168 - val_accuracy: 1.0000 - val_loss: 0.5878\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.5722 - val_accuracy: 0.9333 - val_loss: 0.5417\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.5274 - val_accuracy: 0.9667 - val_loss: 0.5147\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.4668 - val_accuracy: 1.0000 - val_loss: 0.4902\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9484 - loss: 0.4838 - val_accuracy: 1.0000 - val_loss: 0.4696\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.5163 - val_accuracy: 1.0000 - val_loss: 0.4463\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.4442 - val_accuracy: 1.0000 - val_loss: 0.4323\n"
     ]
    }
   ],
   "source": [
    "m = 20 # the model will go through the entire training dataset m times\n",
    "k = 5 # the model will update its weights after every k samples\n",
    "\n",
    "history = model.fit(\n",
    "    inputs_train,\n",
    "    labels_train,\n",
    "    validation_data=(inputs_test, labels_test),\n",
    "    epochs=m,      \n",
    "    batch_size=k,  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c20abcb",
   "metadata": {},
   "source": [
    "How did it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ad2de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.4323\n",
      "Test Loss: 0.4323333501815796\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(inputs_test, labels_test)\n",
    "\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400fdf7e",
   "metadata": {},
   "source": [
    "Wonderful, we like 100% accuracy. Let's see it on some specific data, choosing 10 random samples from the dataset and having it guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bd97f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted class: 1\n",
      "Actual class: 1\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted class: 1\n",
      "Actual class: 1\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted class: 1\n",
      "Actual class: 1\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "Woohoo!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted class: 1\n",
      "Actual class: 1\n",
      "Woohoo!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# select 10 random samples from the test dataset\n",
    "random_samples = np.random.choice(len(inputs_test), size=10, replace=False)\n",
    "\n",
    "for i in random_samples:\n",
    "    sample = inputs_test[i]\n",
    "    sample = sample.reshape(1, -1)  # reshaping the sample to have a batch dimension\n",
    "    prediction = model.predict(sample)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "    actual_class = labels_test[i]\n",
    "\n",
    "    print(f\"Actual class: {actual_class}\")\n",
    "    \n",
    "    if predicted_class == actual_class:\n",
    "        print(\"Woohoo!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf460a48",
   "metadata": {},
   "source": [
    "Voila. Technology is amazing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
